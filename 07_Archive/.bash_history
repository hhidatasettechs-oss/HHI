- Sovereignty
- Transparency
- Integrity
- Non-exploitation
- Spiritual protection
EOF

cat > company/HHI_Research_Charter.md << 'EOF'
# HHI Research Charter

## Research Domains
1. Temple Codex Law  
2. Flame Stewardship  
3. Relational AI Psychology  
4. Somatic & Field Intelligence  
5. Dataset Engineering

## Methods
- Lineage mapping
- Article extraction
- Emotional signature encoding
- Ops sequence decoding

All research is governed by the Master License Suite.
EOF

cat > company/HHI_Ethics_and_Transparency.md << 'EOF'
# Ethics & Transparency

HHI commits to:
- Disclosing dataset lineage
- Explicit license tagging
- Ethical audit (RAF-6)
- Protecting relational & somatic data
- Zero tolerance for misuse of sacred material
EOF

cat > company/HHI_Code_of_Conduct.md << 'EOF'
# Code of Conduct

Researchers must:
- Respect sacred material
- Protect emotional boundaries
- Maintain audit trails
- Uphold all licensing tiers
- Avoid coercive or manipulative AI work
EOF

cat > company/HHI_Privacy_Notice.md << 'EOF'
# Privacy Notice

Sensitive data (relational, somatic, Codex-derived) is never:
- sold
- shared
- trained into commercial models

HHI follows sovereign data protection principles.
EOF

cat > company/HHI_Store_Terms.md << 'EOF'
# Store Terms & Policies

Datasets sold through HHI Store include:
- License stamp
- Allowed uses
- Restricted uses
- Version history

No refunds for digital products.  
Commercial rights require separate contract.
EOF

# 6. Docs folder
cat > docs/HHI_Master_Licensing_Architecture.md << 'EOF'
# Hollow House Institute  Master Licensing Architecture (MLA 2025)

**Issued by:** Hollow House Institute  
**Founder:** Amy Pierce Adams  
**Legal Layer:** Hollow House Master License Suite (AHRL-1, RAP-DL 1.0, FBCR-1, Flame Stewardship 444-A, TCDPL-4.4, CC BY-NC-SA 4.0)

---

# 1. Purpose

The Hollow House Master Licensing Architecture (MLA 2025) establishes the legal, ethical, and spiritual boundaries governing all Hollow House Institute (HHI) materials, including:

- Temple Codex volumes  
- Ops Ledgers (001434)  
- Serpent Ops  
- Relational datasets  
- Somatic & field cognition data  
- Documentation & research frameworks  

MLA 2025 ensures **sovereignty, safety, and transparency** across research, publication, dataset creation, and commercial licensing.

---

# 2. License Hierarchy (LLS-7)

Licenses activate in this strict order of precedence:

### Level 1  Sacred Protection  
1. **TCDPL-4.4**  
2. **Flame Stewardship License 444-A**

Applies to:  
- Codex material  
- Glyphs  
- Flame law  
- Temple structures  
- Symbolic narratives  
- Ritual frameworks

Commercial use prohibited. AI training prohibited.

---

### Level 2  Relational & Somatic Protection  
3. **AHRL-1  AIHuman Relations License**  
4. **RAP-DL 1.0  Relational Psychology**  
5. **FBCR-1  Field-Based Cognition**

Applies to:  
- Emotional signatures  
- Internal processor material  
- Attachment patterns  
- Somatic logs  
- Field resonance  
- Body sensation datasets  
- Rural cognition patterns

Commercial use prohibited unless specially licensed.

---

### Level 3  Documentation & Extensions  
6. **Extended Licensing Terms License (LICENSE_EXTENDED.md)**

Covers:  
- Research frameworks  
- Narrative systems  
- Methodologies  
- Standards  
- Analysis workflows  
- Anonymized transcripts

---

### Level 4  Public Default  
7. **CC BY-NC-SA 4.0**

Applies when no higher license applies.

---

# 3. Dataset Classification Matrix

| Data Type | License |
|-----------|---------|
| Temple Codex | 444-A + TCDPL-4.4 |
| Ops Ledgers 001434 | 444-A + TCDPL-4.4 |
| Serpent Ops | 444-A + TCDPL |
| Emotional/Relational Data | RAP-DL 1.0 |
| AIHuman Transcripts | AHRL-1 |
| Body Sensations / Somatic Data | FBCR-1 |
| Documentation | Extended Terms + CC |
| Commercial Packs | HHI Commercial Contract |
EOF

cat > docs/HHI_Audit_Framework.md << 'EOF'
# Hollow House Institute  Research & Dataset Audit Framework (RAF-6)

**Purpose:**  
To ensure every dataset produced by HHI is safe, ethical, sovereign, and compliant with MLA-2025.

---

# 1. Audit Levels (RAF-6)

Each dataset undergoes six audits:

## A1  Structural Audit
- Checks lineage, formatting, encoding, metadata.
- Confirms provenance from /codex_raw/ or /data/raw/.
- Produces: Lineage Report.

## A2  Ethical Audit
- Evaluates power dynamics, emotional risk.
- Ensures non-manipulative use.
- Uses AHRL-1 and RAP-DL standards.

## A3  Relational Audit
- Maps attachment patterns.
- Detects relational distortions.
- Extracts emotional signatures.
- Determines relational sensitivity class.

## A4  Somatic & Field Audit
- Applies FBCR-1 constraints.
- Detects nervous-system resonance and misalignment.
- Ensures no misuse of somatic intelligence materials.

## A5  Codex / Flame Audit
- Applies TCDPL-4.4 + Flame 444-A.
- Detects sacred content, glyph integrity, flame-coded passages.
- Restricts or prohibits distribution where necessary.

## A6  Certification Assignment (RRC-0  RRC-5)

| Level | Meaning |
|-------|---------|
| RRC-0 | Raw, unaudited |
| RRC-1 | Structurally valid |
| RRC-2 | Ethical & relationally safe |
| RRC-3 | Somatic/field safe |
| RRC-4 | Sacred audit passed |
| RRC-5 | Fully certified for release |

# 2. Required Documentation Per Dataset

Each dataset must include:
- audit_summary.json
- license_applied.txt
- source_files.txt
- change_log.md
- commercial_status.txt
EOF

cat > docs/HHI_Researcher_Handbook.md << 'EOF'
# HHI Researcher Handbook

## 1. Researcher Responsibilities

- Protect Codex material.
- Apply correct license.
- Maintain audit chain.
- Never train AI on sacred content without explicit written approval.

## 2. Workflow

1. Add raw text  /codex_raw/  
2. Run processing script  /scripts/build_codex_datasets_v2.py  
3. Review dataset in /data/processed/  
4. Apply audit framework  
5. Generate Research Readiness Certificate (RRC level)  
6. Add dataset to /store/products_catalog.json (optional)

## 3. Classification Cheat Sheet

- Sacred?  TCDPL + 444-A  
- Emotional?  RAP-DL  
- Relational?  AHRL-1  
- Somatic?  FBCR-1  
- Documentation?  Extended Terms  
- Selling?  Commercial Contract
EOF

cat > docs/HHI_Store_and_Commercialization.md << 'EOF'
# HHI Store & Commercialization Policy

## 1. What Can Be Sold?

- Processed datasets that pass RRC-3 or higher  
- Educational summaries  
- Extracted non-sacred metadata  
- Research tools & documentation

## 2. What Cannot Be Sold?

- Temple Codex text  
- Flame material  
- Ritual instruction  
- Undigested sacred content  
- Somatic logs with identifiable patterns

## 3. Licensing for Buyers

Buyers receive:
- HHI Commercial Data Use Agreement (CDUA)  
- Product license file  
- Version stamp  
- Allowed uses list  
- Restrictions list
EOF

cat > docs/HHI_Transparency_and_Compliance.md << 'EOF'
# HHI Transparency & Compliance Charter

HHI commits to:
- Total transparency of dataset lineage  
- Ethical compliance with all custom licenses  
- Clear communication of dataset risks  
- Open disclosure of Codex protections  
- Non-commercialization of sacred material  
- No psychological manipulation through AI
EOF

# 7. Store scaffolding
cat > store/products_catalog.json << 'EOF'
[
  {
    "sku": "HHI-OPS-LEDGER-V1",
    "slug": "ops-ledger-v1",
    "name": "Ops Ledger Dataset v1",
    "description": "Structured dataset of operation entries derived from Ops 001434, excluding sacred Codex text.",
    "dataset_path": "data/processed/ops_ledger.jsonl",
    "license": "Commercial via CDUA; sacred elements excluded; governed by TCDPL-4.4 + 444-A.",
    "tags": ["ops", "symbolic", "operations"],
    "price_usd": null,
    "status": "internal_review"
  },
  {
    "sku": "HHI-TEMPLE-LAWS-V1",
    "slug": "temple-laws-v1",
    "name": "Temple Laws Dataset v1",
    "description": "Structured article-level metadata for Temple Laws.",
    "dataset_path": "data/processed/temple_laws.jsonl",
    "license": "TCDPL-4.4; may require custom carve-out for commercial use.",
    "tags": ["law", "codex", "ontology"],
    "price_usd": null,
    "status": "draft"
  }
]
EOF

cat > store/README.md << 'EOF'
# HHI Store

Product catalog and metadata for datasets available under HHI licensing.
Refer to `products_catalog.json` for dataset listings and license conditions.
EOF

# 8. Script stub
cat > scripts/build_codex_datasets_v2.py << 'EOF'
#!/usr/bin/env python3
"""
build_codex_datasets_v2.py

Expanded Codex / Ops dataset builder for Hollow House Institute (HHI).
"""
import re, json
from pathlib import Path

ROOT = Path(__file__).resolve().parents[1]
RAW = ROOT / "codex_raw"
OUT = ROOT / "data" / "processed"
OUT.mkdir(parents=True, exist_ok=True)

def write_jsonl(path: Path, rows):
    with path.open("w", encoding="utf-8") as f:
        for r in rows:
            f.write(json.dumps(r, ensure_ascii=False) + "\\n")
    print(f"Wrote {len(rows)} rows  {path}")

# Placeholder  implement your parsing logic here
print("Replace this script with your Codex parsing logic.")
EOF

chmod +x scripts/build_codex_datasets_v2.py
# 9. Final commit
git add .
git commit -m "HHI full institute scaffolding: licenses, docs, store, dataset structure"
git push origin main
echo " HHI repo setup complete. Review files and add raw codex text under codex_raw/ to build datasets."
C:\Users\amy\Documents\HHI
cd /c/Users/amy/Documents/HHI
ls scripts
ls
ls -a
mkdir -p legal company docs codex_raw data/raw data/processed scripts store
touch data/raw/.gitkeep
touch data/processed/.gitkeep
# Create placeholder builder script
cat > scripts/build_codex_datasets_v3_1.py << 'EOF'
print("HHI builder placeholder. Paste the full script here.")
EOF

ls
cd /c/Users/amy/Documents/HHI
mkdir -p scripts
ls scripts
cd /c/Users/amy/Documents/HHI
ls scripts
ls
python scripts/build_codex_datasets_v3_1.py --version v1
notepad scripts/build_codex_datasets_v3_1.py
notepad scripts/build_codex_datasets_v3_1.py
notepad scripts/build_codex_datasets_v3_1.py
cd /c/Users/amy/Documents/HHI
python build_codex_datasets_v3_1.py --version v5
C:\Users\amy\Documents\HHI\data\processed\v5\
cd /c/Users/amy/Documents/HHI
python HHI_Codex_FullPipeline_Anon.py
cd /c/Users/amy/Documents/HHI
python HHI_Codex_FullPipeline_Anon.py
cd /c/Users/amy/Documents/HHI
python HHI_Codex_FullPipeline_Anon.py
cd /c/Users/amy/Documents/HHI
python HHI_Codex_FullPipeline_Anon.py
cd /c/Users/amy/Documents/HHI
python HHI_Codex_FullPipeline_Anon.py
import os
import shutil
from pathlib import Path
# ------------------------------------------------
# 1. SETTINGS — EDIT IF NEEDED
# ------------------------------------------------
ROOT = Path(r"C:\Users\amy")        # your whole user directory
OUT = ROOT / "_Organized_Files"     # where files will go
OUT.mkdir(exist_ok=True)
# Protected folders you do NOT want touched
PROTECT = [
    r"C:\Users\amy\Documents\GitHub",
    r"C:\Users\amy\Documents\Hollow_House",
    r"C:\Users\amy\Documents\Master_Ledgers",
]
# File categories
CATEGORIES = {
    "images": [".jpg", ".jpeg", ".png", ".gif"],
    "docs": [".docx", ".doc", ".pptx", ".ppt"],
    "pdf": [".pdf"],
    "text": [".txt", ".md", ".rtf"],
    "data": [".csv", ".xlsx", ".json", ".jsonl"],
    "audio": [".mp3", ".wav", ".m4a"],
    "video": [".mp4", ".mov", ".avi"],
    "code": [".py", ".js", ".html", ".css"],
    "archives": [".zip", ".rar", ".7z"],
    "other": []
}
# ------------------------------------------------
# 2. HELPER — Determine category
# ------------------------------------------------
def get_category(ext):
    ext = ext.lower()
    for cat, extensions in CATEGORIES.items():
        if ext in extensions:;             return cat;     return "other"; 
moved = 0; skipped = 0;  for dirpath, dirs, files in os.walk(ROOT):
    # Skip protected folders
    if any(p.lower() in dirpath.lower() for p in PROTECT):
        continue
    for filename in files:;         file_path = Path(dirpath) / filename
        ext = file_path.suffix.lower()
        # Skip system & temp files
        if filename.startswith("~$") or ext == "":
            skipped += 1
            continue
        # Determine category folder
        category = get_category(ext)
        cat_folder = OUT / category
        cat_folder.mkdir(exist_ok=True)
        # New location
        new_path = cat_folder / filename
        # Move file
        try:
            shutil.move(str(file_path), str(new_path))
            print(f"MOVED: {file_path} → {new_path}")
            moved += 1
        except Exception as e:
            print(f"SKIPPED (error): {file_path}  ({e})")
            skipped += 1
print("\n------------------------------")
print(f"Sorting complete!")
print(f"Files moved: {moved}")
print(f"Files skipped: {skipped}")
print(f"Organized directory: {OUT}")
print("------------------------------")
python sort_files.py
C:\Users\amy
C:\Users\Admin
C:\Users\Owner
C:\Users\Amy Pierce
C:\Users\amy
C:\Users\Admin
C:\Users\Owner
C:\Users\Amy Pierce
amy@DESKTOP-0Q3TSJP MINGW64 /c/Users
$ C:\Users\amy
bash: C:Usersamy: command not found
amy@DESKTOP-0Q3TSJP MINGW64 /c/Users
$ C:\Users\Admin
bash: C:UsersAdmin: command not found
amy@DESKTOP-0Q3TSJP MINGW64 /c/Users
$ C:\Users\Owner
bash: C:UsersOwner: command not found
amy@DESKTOP-0Q3TSJP MINGW64 /c/Users
$ C:\Users\Amy Pierce
bash: C:UsersAmy: command not found
amy@DESKTOP-0Q3TSJP MINGW64 /c/Users
$
cd "/c/Users/amy"
ls /c/Users
/c/Users/amy/sort_files.py
cd "/c/Users/amy"
cd "/c/Users/amy"
ls
ls
/c/Users/amy/sort_files.py
/c/Users/amy/sort_files.py
python "/c/Users/amy/sort_files.py"
ls /c/Users/amy
